% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/FitnessFunction.R
\name{FitnessFunction}
\alias{FitnessFunction}
\title{FitnessFunction Class}
\description{
Implements a fitness function for \pkg{mlr3} as \code{R6} class \code{FitnessFunction}. An object of that class
contains all relevant informations that are necessary to conduct tuning (\code{mlr3::Task}, \code{mlr3::Learner}, \code{mlr3::Resampling}, \code{mlr3::Measure}s,
\code{paradox::ParamSet}).
After defining a fitness function, we can use it to predict the generalization error of a specific learner configuration
defined by it's hyperparameter (using \code{$eval()}).
The \code{FitnessFunction} class is the basis for further tuning strategies, i.e., grid or random search.
}
\section{Usage}{
\preformatted{# Construction
ff = FitnessFunction$new(task, learner, resampling, param_set, 
  ctrl = tune_control())

# Public members
ff$task
ff$learner
ff$resampling
ff$param_set
ff$ctrl
ff$hooks
ff$bmr

# Public methods
ff$eval(x)
ff$eval_vectorized(xts)
ff$get_best()
ff$run_hooks(id)
}
}

\section{Arguments}{

\itemize{
\item \code{task} (\code{mlr3::Task}):
The task that we want to evaluate.
\item \code{learner} (\code{mlr3::Learner}):
The learner that we want to evaluate.
\item \code{resampling} (\code{mlr3::Resampling}):
The Resampling method that is used to evaluate the learner.
\item \code{param_set} (\link[paradox:ParamSet]{paradox::ParamSet}):
Parameter set to define the hyperparameter space.
\item \code{ctrl} (\code{list()}):
See \code{\link[=tune_control]{tune_control()}}.
\item \code{xt} (\code{list()}):
A specific (transformed) parameter configuration given as named list (e.g. for rpart \code{list(cp = 0.05, minsplit = 4)}).
\item \code{xts} (\code{list()}):
Collection of multiple (transformed) parameter values gained that is, for example, gained from a tuning strategy like grid search (see \code{?paradox::generate_design_grid}).
\item \code{id} (\code{character(1)}):
Identifier of a hook.
}
}

\section{Details}{

\itemize{
\item \code{$new()} creates a new object of class \link{FitnessFunction}.
\item \code{$task} (\code{mlr3::Task}) the task for which the tuning should be conducted.
\item \code{$learner} (\code{mlr3::Learner}) the algorithm for which the tuning should be conducted.
\item \code{$resampling} (\code{mlr3::Resampling}) strategy to evaluate a parameter setting
\item \code{$param_set} (\code{paradox::ParamSet}) parameter space given to the \code{Tuner} object to generate parameter values.
\item \code{$ctrl} (\code{list()}) execution control object for tuning (see \code{?tune_control}).
\item \code{$hooks} (\code{list()}) list of functions that could be executed with \code{run_hooks()}.
\item \code{$bmr} (\code{mlr3::BenchmarkResult}) object that contains all tuning results as \code{BenchmarkResult} object (see \code{?BenchmarkResult}).
\item \code{$eval(xt)} evaluates the (transformed) parameter setting \code{xt} (\code{list}) for the given learner and resampling.
\item \code{$eval_vectorized(xts)} performs resampling for multiple (transformed) parameter settings \code{xts} (list of lists).
\item \code{$get_best()}  get best parameter configuration from the \code{BenchmarkResult} object.
\item \code{$run_hooks()} run a function that runs on the whole \code{FitnessFunction} object.
}
}

\examples{
# Object required to define the fitness function:
task = mlr3::mlr_tasks$get("iris")
learner = mlr3::mlr_learners$get("classif.rpart")
resampling = mlr3::mlr_resamplings$get("holdout")
measures = mlr3::mlr_measures$mget("classif.mmce")
task$measures = measures
param_set = paradox::ParamSet$new(params = list(
  paradox::ParamDbl$new("cp", lower = 0.001, upper = 0.1)))

ff = FitnessFunction$new(
  task = task,
  learner = learner,
  resampling = resampling,
  param_set = param_set
)

ff$eval(data.table(cp = 0.05, minsplit = 5))
ff$eval(data.table(cp = 0.01, minsplit = 3))
ff$get_best()
}
\concept{FitnessFunction}
\keyword{internal}
