% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/AutoTuner.R
\docType{data}
\name{AutoTuner}
\alias{AutoTuner}
\title{AutoTuner}
\format{\link[R6:R6Class]{R6::R6Class} object inheriting from \link[mlr3:Learner]{mlr3::Learner}.}
\description{
The \code{AutoTuner} is a \link[mlr3:Learner]{mlr3::Learner} which tunes a subordinate learner via resampling.
The best found configuration is then used to train a model on the complete training data.
Note that this class allows to perform nested resampling by passing an \link{AutoTuner} object to \code{\link[mlr3:resample]{mlr3::resample()}}
or \code{\link[mlr3:benchmark]{mlr3::benchmark()}}.
}
\section{Construction}{
\preformatted{at = AutoTuner$new(learner, resampling, measures, param_set, terminator,
  tuner, bm_args = list(), id = "autotuner")
}
\itemize{
\item \code{learner} :: \link[mlr3:Learner]{mlr3::Learner} | \link[mlr3:mlr_sugar]{mlr3::mlr_sugar}\cr
Learner to tune.
\item \code{resampling} :: \link[mlr3:Resampling]{mlr3::Resampling} | \link[mlr3:mlr_sugar]{mlr3::mlr_sugar}\cr
Resampling strategy used to assess the performance of the learner on the (subset of) the
\item \code{measures} :: list of \link[mlr3:Measure]{mlr3::Measure} | \link[mlr3:mlr_sugar]{mlr3::mlr_sugar}\cr
Performance measures. The first one is optimized.
\item \code{param_set} :: \link[paradox:ParamSet]{paradox::ParamSet}\cr
Hyperparameter search space.
\item \code{terminator} :: \link{Terminator}\cr
When to stop tuning.
\item \code{tuner} :: \link{Tuner}\cr
Tuning algorithm to run.
\item \code{bm_args} :: \code{list()}\cr
Further arguments for \code{\link[mlr3:benchmark]{mlr3::benchmark()}}, see \link{TuningInstance}.
\item \code{id} :: \code{character(1)}\cr
Name of the learner.
}
}

\section{Fields}{

All fields from \link{Learner}, and additionally:
\itemize{
\item \code{learner} :: \link[mlr3:Learner]{mlr3::Learner}\cr
Subordinate learner. After \code{train()} of the \code{AutoTuner} has been executed,
this learner stores the final model and is parametrized with the best found solution.
\item \code{resampling} :: \link[mlr3:Resampling]{mlr3::Resampling}.
\item \code{measures} :: list of \link[mlr3:Measure]{mlr3::Measure}.
\item \code{tune_ps} :: \link[paradox:ParamSet]{paradox::ParamSet}\cr
Hyperparameter search space.
\item \code{terminator} :: \link{Terminator}.
\item \code{tuner} :: \link{Tuner}.
\item \code{store_bmr} :: \code{logical(1)}\cr
If \code{TRUE}, stores the benchmark result as slot \code{$bmr}.
\item \code{tune_path} :: \code{\link[data.table:data.table]{data.table::data.table()}}\cr
Only stored if \code{store_bmr} has been set to \code{TRUE}.
This is the archive of the stored \link[mlr3:BenchmarkResult]{mlr3::BenchmarkResult} with hyperparameters as separate columns.
}
}

\section{Methods}{

See \link[mlr3:Learner]{mlr3::Learner}.
}

\examples{
library(mlr3)
library(paradox)
task = tsk("iris")
learner = lrn("classif.rpart")
resampling = rsmp("holdout")
measures = msr("classif.ce")
param_set = ParamSet$new(
  params = list(ParamDbl$new("cp", lower = 0.001, upper = 0.1)))

terminator = term("evals", n_evals = 5)
tuner = tnr("grid_search")
at = AutoTuner$new(learner, resampling, measures, param_set, terminator, tuner)
at$store_bmr = TRUE

at$train(task)
at$model
at$learner
}
\concept{Learner}
\keyword{datasets}
