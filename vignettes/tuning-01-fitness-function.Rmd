---
title: "Introduction to Fitness Functions"
author: "Daniel Schalk"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Introduction to Fitness Functions}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
library(mlr3tuning)
knitr::opts_knit$set(
  datatable.print.keys = FALSE,
  datatable.print.class = TRUE
)
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
set.seed(123)
```

`mlr3tuning` is an extension of `mlr3` that includes tuning.

## Basis of Tuning 

Before we can tune hyperparameters, it is necessary to define the learner, task, how to evaluate a hyperparameter setting, and the hyperparameter space.
Here, we will stick to the popular [iris data set](https://en.wikipedia.org/wiki/Iris_flower_data_set) and a decision tree from `rpart`:

```{r}
task = mlr3::mlr_tasks$get("iris")
learner = mlr3::mlr_learners$get("classif.rpart")
resampling = mlr3::mlr_resamplings$get("holdout")
measures = mlr3::mlr_measures$mget("mmce")
param_set = paradox::ParamSet$new(params = list(paradox::ParamDbl$new("cp", lower = 0.001, upper = 0.1)))
```

## Define Fitness Function

With that basis we can define a fitness function:

```{r}
ff = FitnessFunction$new(
  task = task,
  learner = learner,
  resampling = resampling,
  measures = measures,
  param_set = param_set
)
```

At this point there are no results since have not computed anything jet:
```{r}
ff$bmr
```



## Evaluate a Parameter Configuration

The results of any computation are stored as `mlr3::BenchmarkResult`

