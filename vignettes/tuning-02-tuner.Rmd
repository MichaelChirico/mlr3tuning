---
title: "Introduction to Tuner"
author: "Daniel Schalk"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Introduction to Tuner}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
library(mlr3tuning)
knitr::opts_knit$set(
  datatable.print.keys = FALSE,
  datatable.print.class = TRUE
)
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
set.seed(123)
```

`mlr3tuning` is an extension of `mlr3` that includes tuning.

## Basis of Tuning 

Before we can tune hyperparameters, it is necessary to define the learner, task, how to evaluate a hyperparameter setting, and the hyperparameter space.
Here, we will stick to the popular [iris data set](https://en.wikipedia.org/wiki/Iris_flower_data_set) and a decision tree from `rpart`:

```{r}
task = mlr3::mlr_tasks$get("iris")
learner = mlr3::mlr_learners$get("classif.rpart")
resampling = mlr3::mlr_resamplings$get("holdout")
measures = mlr3::mlr_measures$mget("mmce")
param_set = paradox::ParamSet$new(params = list(paradox::ParamDbl$new("cp", lower = 0.001, upper = 0.1)))
```

## Define Fitness Function

With that basis we can define a fitness function:

```{r}
ff = FitnessFunction$new(
  task = task,
  learner = learner,
  resampling = resampling,
  measures = measures,
  param_set = param_set
)
```

At this point there are no results since have not computed anything jet:
```{r}
ff$bmr
```

However, the defined parameter space that is used for later search strategies is stored within the public member `param_set`:
```{r}
ff$param_set
```

## Evaluate a Parameter Configuration

With the `$eval()` member function we can evaluate a single parameter configuration given as names list:
```{r}
ff$eval(list(cp = 0.05, minsplit = 5))
```

The results of any computation are stored as `mlr3::BenchmarkResult`:
```{r}
ff$bmr
ff$bmr$data
ff$bmr$data$learner
```
